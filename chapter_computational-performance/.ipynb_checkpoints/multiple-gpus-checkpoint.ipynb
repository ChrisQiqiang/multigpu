{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多GPU计算\n",
    "\n",
    "本节中我们将展示如何使用多块GPU计算，例如，使用多块GPU训练同一个模型。正如所期望的那样，运行本节中的程序需要至少2块GPU。事实上，一台机器上安装多块GPU很常见，这是因为主板上通常会有多个PCIe插槽。如果正确安装了NVIDIA驱动，我们可以通过`nvidia-smi`命令来查看当前计算机上的全部GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 24 21:01:00 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla M60           On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   27C    P8    22W / 150W |      0MiB /  7618MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla M60           On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   30C    P8    22W / 150W |      0MiB /  7618MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[“自动并行计算”](auto-parallelism.ipynb)一节介绍过，大部分运算可以使用所有的CPU的全部计算资源，或者单块GPU的全部计算资源。但如果使用多块GPU训练模型，我们仍然需要实现相应的算法。这些算法中最常用的叫作数据并行。\n",
    "\n",
    "\n",
    "## 数据并行\n",
    "\n",
    "数据并行目前是深度学习里使用最广泛的将模型训练任务划分到多块GPU的方法。回忆一下我们在[“小批量随机梯度下降”](../chapter_optimization/minibatch-sgd.ipynb)一节中介绍的使用优化算法训练模型的过程。下面我们就以小批量随机梯度下降为例来介绍数据并行是如何工作的。\n",
    "\n",
    "假设一台机器上有$k$块GPU。给定需要训练的模型，每块GPU及其相应的显存将分别独立维护一份完整的模型参数。在模型训练的任意一次迭代中，给定一个随机小批量，我们将该批量中的样本划分成$k$份并分给每块显卡的显存一份。然后，每块GPU将根据相应显存所分到的小批量子集和所维护的模型参数分别计算模型参数的本地梯度。接下来，我们把$k$块显卡的显存上的本地梯度相加，便得到当前的小批量随机梯度。之后，每块GPU都使用这个小批量随机梯度分别更新相应显存所维护的那一份完整的模型参数。图8.1描绘了使用2块GPU的数据并行下的小批量随机梯度的计算。\n",
    "\n",
    "![使用2块GPU的数据并行下的小批量随机梯度的计算](../img/data-parallel.svg)\n",
    "\n",
    "为了从零开始实现多GPU训练中的数据并行，让我们先导入需要的包或模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, nd\n",
    "from mxnet.gluon import loss as gloss\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "\n",
    "我们使用[“卷积神经网络（LeNet）”](../chapter_convolutional-neural-networks/lenet.ipynb)一节里介绍的LeNet来作为本节的样例模型。这里的模型实现部分只用到了`NDArray`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化模型参数\n",
    "scale = 0.01\n",
    "W1 = nd.random.normal(scale=scale, shape=(20, 1, 3, 3))\n",
    "b1 = nd.zeros(shape=20)\n",
    "W2 = nd.random.normal(scale=scale, shape=(50, 20, 5, 5))\n",
    "b2 = nd.zeros(shape=50)\n",
    "W3 = nd.random.normal(scale=scale, shape=(800, 128))\n",
    "b3 = nd.zeros(shape=128)\n",
    "W4 = nd.random.normal(scale=scale, shape=(128, 10))\n",
    "b4 = nd.zeros(shape=10)\n",
    "params = [W1, b1, W2, b2, W3, b3, W4, b4]\n",
    "\n",
    "# 定义模型\n",
    "def lenet(X, params):\n",
    "    h1_conv = nd.Convolution(data=X, weight=params[0], bias=params[1],\n",
    "                             kernel=(3, 3), num_filter=20)\n",
    "    h1_activation = nd.relu(h1_conv)\n",
    "    h1 = nd.Pooling(data=h1_activation, pool_type='avg', kernel=(2, 2),\n",
    "                    stride=(2, 2))\n",
    "    h2_conv = nd.Convolution(data=h1, weight=params[2], bias=params[3],\n",
    "                             kernel=(5, 5), num_filter=50)\n",
    "    h2_activation = nd.relu(h2_conv)\n",
    "    h2 = nd.Pooling(data=h2_activation, pool_type='avg', kernel=(2, 2),\n",
    "                    stride=(2, 2))\n",
    "    h2 = nd.flatten(h2)\n",
    "    h3_linear = nd.dot(h2, params[4]) + params[5]\n",
    "    h3 = nd.relu(h3_linear)\n",
    "    y_hat = nd.dot(h3, params[6]) + params[7]\n",
    "    return y_hat\n",
    "\n",
    "# 交叉熵损失函数\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多GPU之间同步数据\n",
    "\n",
    "我们需要实现一些多GPU之间同步数据的辅助函数。下面的`get_params`函数将模型参数复制到某块显卡的显存并初始化梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "def get_params(params, ctx):\n",
    "    new_params = [p.copyto(ctx) for p in params]\n",
    "    for p in new_params:\n",
    "        p.attach_grad()\n",
    "    return new_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试把模型参数`params`复制到`gpu(0)`上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1 weight: \n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "<NDArray 20 @gpu(0)>\n",
      "b1 grad: \n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "<NDArray 20 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "new_params = get_params(params, mx.gpu(0))\n",
    "print('b1 weight:', new_params[1])\n",
    "print('b1 grad:', new_params[1].grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定分布在多块显卡的显存之间的数据。下面的`allreduce`函数可以把各块显卡的显存上的数据加起来，然后再广播到所有的显存上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def bit_product_sum(x, y):\n",
    "    return sum([item[0] * item[1] for item in zip(x, y)])\n",
    "\n",
    "def allreduce(data):\n",
    "    for i in range(1, len(data)):\n",
    "        tmp = data[i].copyto(data[0].context)\n",
    "        x = data[0].asnumpy()\n",
    "        y = tmp.asnumpy()\n",
    "        assert x.shape == y.shape\n",
    "        if x.ndim == 1:#只计算bias的grad向量的余弦距离。\n",
    "            cos = bit_product_sum(x, y) / (np.sqrt(bit_product_sum(x, x)) * np.sqrt(bit_product_sum(y, y)))\n",
    "            print(cos)\n",
    "        for i in range(len(data[0])):\n",
    "            data[0][:] += tmp\n",
    "    for i in range(1, len(data)):\n",
    "        data[0].copyto(data[i])\n",
    "        \n",
    "def ssp_allreduce(data):\n",
    "    for i in range(1, len(data) // 2): #加的时候是一半的数据，分发的时候所有节点否分发\n",
    "        data[0][:] += data[i].copyto(data[0].context)\n",
    "    for i in range(1, len(data)):\n",
    "        data[0].copyto(data[i])\n",
    "        \n",
    "def partial_allreduce(data):\n",
    "    for i in range(1, len(data)):\n",
    "        tmp = data[i].copyto(data[0].context)\n",
    "        l = len(data[0]) // 2\n",
    "        data[0][:l] += tmp[:l]\n",
    "        if i < len(data) // 2:\n",
    "            data[0][l:] += tmp[:l]\n",
    "    data[0][l:] += data[0][l:]\n",
    "#         for j in range(len(data[0])): #加的时候是一半的数据，分发的时候所有节点否分发\n",
    "#             if(j < len(data[0]) // 2):\n",
    "#                 data[0][j] += tmp[j]\n",
    "#             elif(i < len(data) // 2):\n",
    "#                 data[0][j] += tmp[j]   #后一半的参数只用一半的batchsize\n",
    "#             else:\n",
    "#                 pass\n",
    "#     for i in range(len(data[0])):\n",
    "#         if i >= len(data[0])// 2:\n",
    "#             data[0][i] = data[0][i] * 2\n",
    "    for i in range(1, len(data)):\n",
    "        data[0].copyto(data[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单测试一下`allreduce`函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on: [gpu(0), gpu(1)]\n",
      "0.6270066624853188\n",
      "0.375800393482649\n",
      "0.3683323186189875\n",
      "0.012304025234070615\n",
      "0.21864679494113257\n",
      "0.43763146199423053\n",
      "0.22895182883467718\n",
      "0.15126383649197325\n",
      "0.2911170016637901\n",
      "0.4542592248452909\n",
      "0.5550275319771916\n",
      "0.7019430464594684\n",
      "0.2035858724639278\n",
      "0.6130217086260753\n",
      "0.5778098551350812\n",
      "0.32671798415491354\n",
      "0.9696115599566906\n",
      "0.7949097933398012\n",
      "-0.0181594870060467\n",
      "0.36653036158647034\n",
      "-0.22423850871136838\n",
      "0.10104356656728555\n",
      "0.053406545904972895\n",
      "-0.15557698036244558\n",
      "0.9856989091386835\n",
      "0.973104650748628\n",
      "0.9268395937703555\n",
      "0.69690980452599\n",
      "0.9733565452819621\n",
      "0.8020597742872885\n",
      "0.6055072360865549\n",
      "0.12213908475829033\n",
      "0.9912423747543821\n",
      "0.9205521890120534\n",
      "0.7616992316848378\n",
      "-0.3859419122401858\n",
      "0.9903954033318689\n",
      "0.8523497537944944\n",
      "0.9101272865862872\n",
      "0.663728183922044\n",
      "0.9961419104521523\n",
      "0.9719548675601657\n",
      "0.9131093767000753\n",
      "-0.06584185381197631\n",
      "0.9877697326613438\n",
      "0.9555189754186717\n",
      "0.7916097456585599\n",
      "-0.13590433456905376\n",
      "0.9964978962897636\n",
      "0.9737687262713121\n",
      "0.8596614591045174\n",
      "0.036052630769205736\n",
      "-0.7960236476081989\n",
      "-0.08765214997980163\n",
      "-0.2874397955409813\n",
      "0.04073521600895601\n",
      "0.9141330350868638\n",
      "0.795652348100223\n",
      "0.7049239010774686\n",
      "0.7686335080773482\n",
      "-0.3393745347044368\n",
      "0.5448457831268498\n",
      "-0.23603108553255014\n",
      "-0.4295039991245794\n",
      "0.9999726056987018\n",
      "0.9994531660079783\n",
      "0.9141330710134655\n",
      "0.12659597521186808\n",
      "0.9768834048282163\n",
      "0.9894906883434978\n",
      "0.7325984662462746\n",
      "-0.2349228442897286\n",
      "-0.05355682167432706\n",
      "-0.9290997156507839\n",
      "-0.7624858585506131\n",
      "-0.6074352560855688\n",
      "0.9934285347306656\n",
      "0.9986423714856143\n",
      "0.939805909552119\n",
      "-0.04767786743394936\n",
      "0.9867814462768625\n",
      "0.24674813243116311\n",
      "-0.9634545239796382\n",
      "0.03421329385427777\n",
      "0.9994400847189234\n",
      "0.9024401759748801\n",
      "-0.26761755695253336\n",
      "0.06623055595615318\n",
      "0.9998396080987775\n",
      "0.9897074802716793\n",
      "0.9342174708710803\n",
      "0.7904149906973646\n",
      "0.9912718147420367\n",
      "0.9312748348692818\n",
      "0.9307535019803858\n",
      "0.107033011382179\n",
      "0.755367731312528\n",
      "-0.47274865869466387\n",
      "-0.009728045822754982\n",
      "0.06318666398743675\n",
      "-0.9134410287991628\n",
      "-0.9796414896595103\n",
      "-0.9803401863060321\n",
      "-0.7946230187921717\n",
      "0.4195745700313673\n",
      "0.959343404878794\n",
      "0.9689637183836182\n",
      "-0.2368913547019184\n",
      "0.19876362349533888\n",
      "-0.70755698134683\n",
      "-1.0000000146487795\n",
      "0.23790681562511437\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0314356939014446\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.19426968934931546\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.22842534852603524\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.08062240222729163\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.4063390620259672\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.4958847681148872\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.05778285894187085\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2033856460919176\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5450213994142871\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.6297699851367763\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.4964044170898061\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.5136295685766212\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.42038938114244584\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.06379268242493367\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.055468099871107415\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.32991344023741187\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.006600782103646881\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.568084857836605\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5244323410842048\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.3642884747978928\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.051965852019359736\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.0653376582181533\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.318646811577896\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.1885604175486659\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5040198693384808\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.08060239905623541\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.6682340846656015\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.16889328846105656\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.1483151334950351\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.413140750962493\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.47553440275722\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.4686386925396651\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.8581000140410493\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.6156456711072366\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.18509412596009797\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.20228944401267526\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.052286265819188854\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2742295922441939\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.19572127477421436\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.2373474913090247\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.18716683739435408\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.023043768332826637\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.16223190827005024\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.08365002964615484\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.14561537719611387\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.004403488746752421\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.17181398215799737\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.04643229253592154\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.4628813738452763\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.18198125134318924\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.25692217739405016\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.48101641372876686\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.3265486024096638\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.02594420892238903\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.10595592307083108\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.017063843021668038\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.06280940171294866\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.6637790358271684\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.3353029935154353\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.25407945534780507\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.11455331425265386\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.17350755299741646\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.2101379348665857\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2570604788229272\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2391165192638325\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.08126896188656567\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.24792266676073638\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.4845368094724705\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.22748455884653138\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.7396786903432448\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.047302555153127424\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.5194804357830465\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.30533260066908596\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.633941504538424\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.6588457266993454\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.015034346716778479\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.4612911421266315\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.6645665998112427\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.19459611400185148\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.009850496072084497\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.3108671795041059\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5452890637809852\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.06854799294019887\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.07709439135132132\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.1486680140311808\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.1278726341388931\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.17340763805411932\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.013150184704510426\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.05902570534557876\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.20654512432062466\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.20472641647504547\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.13525106732145073\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.27743151068552124\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.0975969335296907\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.3927240962635766\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.4513557457085222\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.18014276763864734\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.1471930814496036\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.18135544911881285\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.31057633467677187\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.05457228978763386\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.6541439886409509\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.13354127690537987\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.294259993736755\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.06781956979540633\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.7554190623894401\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.21751816359346607\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.08597547898957908\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.12921281179316185\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5228729353344238\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.003536146456061981\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.11431244956695942\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.27448213559660795\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.45093412381180464\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.14708598713441334\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.16130574115832055\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.3059423133695469\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.36913811125121815\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.43892469410211976\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.13321005335201838\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.3210929608171622\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.3392998726541588\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.6504321129615275\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.039463536008528824\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2591634006119571\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.33247193191798174\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.25544674848206184\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.04674850866725692\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.0788027054580066\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.5077206758366724\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.5406909273179883\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.15893886117870212\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.4924277144238155\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.07545445067674618\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2614941247145914\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.016248794307321974\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.30580575092203227\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.17073069795348247\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.4307309803204328\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.269774360034852\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.06374216575251807\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.23379059297721932\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.3821918322326523\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2913567905449837\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.35336697785401766\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.3543718612123197\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.22462137200870483\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.354528894665771\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.09982531452238637\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.40826550603818806\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.3387009382487858\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.4213902826306807\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.7835361359827184\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.5167663824019835\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.1099941233852845\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.6529006826725464\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.3689853204911561\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.1309316275906488\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.14924332314505603\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.20729355471143215\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.5669601307377026\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.002052705483329088\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.38861808635011236\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.11061547462887121\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.6576653536704146\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.23883847897623806\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.011959750589429568\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.3006352498606927\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.04205325949232959\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.386973142837299\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.03949321891630062\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.17988370256328778\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.018586758675337312\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.12884349283966895\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5059407898100268\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.5864147076154462\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.014818698304301112\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5004423375740288\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.40020482002774704\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.3305189584240315\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.34431011187414073\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.16683066063240645\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5427290305337285\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.4911029943932852\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.26628317125198053\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2508291613143403\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.45894841138932707\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.43237486265741026\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.23049237556182733\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.1375745690446322\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2363487565981681\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.25961490013717575\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.09255532616328059\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.19605808478477513\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5266359772462145\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.23343606411426124\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2786194107464403\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.11531550839195127\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.16082049770317028\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.2740013945323845\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.05839647427785984\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.5634637893030987\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.15757422882886538\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.003111907957146364\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.14565468731932948\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "0.596761259609783\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-0.7510258418321326\n",
      "epoch 1, time 44.5 sec, test acc 0.10\n"
     ]
    }
   ],
   "source": [
    "train(num_gpus=2, batch_size=256, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before allreduce: [\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "<NDArray 4x2 @gpu(0)>, \n",
      "[[2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]]\n",
      "<NDArray 4x2 @gpu(1)>]\n",
      "reduce process:=======================\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "[0.9999999999999998, 0.9999999999999998, 0.9999999999999998, 0.9999999999999998]\n",
      "after allreduce: [\n",
      "[[3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]]\n",
      "<NDArray 4x2 @gpu(0)>, \n",
      "[[3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]]\n",
      "<NDArray 4x2 @gpu(1)>]\n"
     ]
    }
   ],
   "source": [
    "data = [nd.ones((4, 2), ctx=mx.gpu(i)) * (i + 1) for i in range(2)]\n",
    "print('before allreduce:', data)\n",
    "# partial_allreduce(data)\n",
    "allreduce(data)\n",
    "print('after allreduce:', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个批量的数据样本，下面的`split_and_load`函数可以将其划分并复制到各块显卡的显存上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [],
   "source": [
    "def split_and_load(data, ctx):\n",
    "    n, k = data.shape[0], len(ctx)\n",
    "    m = n // k  # 简单起见，假设可以整除\n",
    "    assert m * k == n, '# examples is not divided by # devices.'\n",
    "    return [data[i * m: (i + 1) * m].as_in_context(ctx[i]) for i in range(k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们试着用`split_and_load`函数将6个数据样本平均分给2块显卡的显存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  \n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11.]\n",
      " [12. 13. 14. 15.]\n",
      " [16. 17. 18. 19.]\n",
      " [20. 21. 22. 23.]]\n",
      "<NDArray 6x4 @cpu(0)>\n",
      "load into [gpu(0), gpu(1)]\n",
      "output: [\n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11.]]\n",
      "<NDArray 3x4 @gpu(0)>, \n",
      "[[12. 13. 14. 15.]\n",
      " [16. 17. 18. 19.]\n",
      " [20. 21. 22. 23.]]\n",
      "<NDArray 3x4 @gpu(1)>]\n"
     ]
    }
   ],
   "source": [
    "batch = nd.arange(24).reshape((6, 4))\n",
    "ctx = [mx.gpu(0), mx.gpu(1)]\n",
    "splitted = split_and_load(batch, ctx)\n",
    "print('input: ', batch)\n",
    "print('load into', ctx)\n",
    "print('output:', splitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单个小批量上的多GPU训练\n",
    "\n",
    "现在我们可以实现单个小批量上的多GPU训练了。它的实现主要依据本节介绍的数据并行方法。我们将使用刚刚定义的多GPU之间同步数据的辅助函数`allreduce`和`split_and_load`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(X, y, gpu_params, ctx, lr):\n",
    "    # 当ctx包含多块GPU及相应的显存时，将小批量数据样本划分并复制到各个显存上\n",
    "    gpu_Xs, gpu_ys = split_and_load(X, ctx), split_and_load(y, ctx) \n",
    "    with autograd.record():  # 在各块GPU上分别计算损失\n",
    "        ls = [loss(lenet(gpu_X, gpu_W), gpu_y)\n",
    "              for gpu_X, gpu_y, gpu_W in zip(gpu_Xs, gpu_ys, gpu_params)]\n",
    "    for l in ls:  # 在各块GPU上分别反向传播\n",
    "        l.backward()\n",
    "    # 把各块显卡的显存上的梯度加起来，然后广播到所有显存上 \n",
    "#     print(\"grad number is:\", len(gpu_params[0]))\n",
    "    for i in range(len(gpu_params[0])):\n",
    "        allreduce([gpu_params[c][i].grad for c in range(len(ctx))])\n",
    "    for param in gpu_params:  # 在各块显卡的显存上分别更新模型参数\n",
    "        d2l.sgd(param, lr, X.shape[0])  # 这里使用了完整批量大小\n",
    "\n",
    "        \n",
    "def ssp_train(X, y, gpu_params, ctx, lr):\n",
    "    gpu_Xs, gpu_ys = split_and_load(X, ctx), split_and_load(y, ctx) \n",
    "    with autograd.record():  # 在各块GPU上分别计算损失\n",
    "        ls = [loss(lenet(gpu_X, gpu_W), gpu_y)\n",
    "              for gpu_X, gpu_y, gpu_W in zip(gpu_Xs, gpu_ys, gpu_params)]\n",
    "    for l in ls:  # 在各块GPU上分别反向传播\n",
    "        l.backward()\n",
    "    # 把各块显卡的显存上的梯度加起来，然后广播到所有显存上\n",
    "    for i in range(len(gpu_params[0])):\n",
    "        ssp_allreduce([gpu_params[c][i].grad for c in range(len(ctx))])\n",
    "    for param in gpu_params:  # 在各块显卡的显存上分别更新模型参数\n",
    "        d2l.sgd(param, lr, X.shape[0] // 2)  # 这里使用了完整批量大小\n",
    "\n",
    "def partial_train(X, y, gpu_params, ctx, lr):\n",
    "    gpu_Xs, gpu_ys = split_and_load(X, ctx), split_and_load(y, ctx) \n",
    "    with autograd.record():  # 在各块GPU上分别计算损失\n",
    "        ls = [loss(lenet(gpu_X, gpu_W), gpu_y)\n",
    "              for gpu_X, gpu_y, gpu_W in zip(gpu_Xs, gpu_ys, gpu_params)]\n",
    "    for l in ls:  # 在各块GPU上分别反向传播\n",
    "        l.backward()\n",
    "\n",
    "#     loss_curve.append(sum(sum(ls) / len(ls)) / len(sum(ls) / len(ls)))\n",
    "    # 把各块显卡的显存上的梯度加起来，然后广播到所有显存上\n",
    "    for i in range(len(gpu_params[0])):\n",
    "        partial_allreduce([gpu_params[c][i].grad for c in range(len(ctx))])\n",
    "    for param in gpu_params:  # 在各块显卡的显存上分别更新模型参数\n",
    "        d2l.sgd(param, lr, X.shape[0])  # 这里使用了完整批量大小\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练函数\n",
    "\n",
    "现在我们可以定义训练函数了。这里的训练函数和[“softmax回归的从零开始实现”](../chapter_deep-learning-basics/softmax-regression-scratch.ipynb)一节定义的训练函数`train_ch3`有所不同。值得强调的是，在这里我们需要依据数据并行将完整的模型参数复制到多块显卡的显存上，并在每次迭代时对单个小批量进行多GPU训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_gpus, batch_size, lr):\n",
    "    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "    ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "    print('running on:', ctx)\n",
    "    # 将模型参数复制到num_gpus块显卡的显存上\n",
    "    gpu_params = [get_params(params, c) for c in ctx]\n",
    "    for epoch in range(1):\n",
    "        start = time.time()\n",
    "        for X, y in train_iter:\n",
    "            # 对单个小批量进行多GPU训练\n",
    "#             print(\"train\")\n",
    "            train_batch(X, y, gpu_params, ctx, lr)\n",
    "            nd.waitall()\n",
    "        train_time = time.time() - start\n",
    "\n",
    "        def net(x):  # 在gpu(0)上验证模型\n",
    "            return lenet(x, gpu_params[0])\n",
    "\n",
    "        test_acc = d2l.evaluate_accuracy(test_iter, net, ctx[0])\n",
    "        print('epoch %d, time %.1f sec, test acc %.2f'\n",
    "              % (epoch + 1, train_time, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多GPU训练实验\n",
    "\n",
    "让我们先从单GPU训练开始。设批量大小为256，学习率为0.2。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on: [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, time 10.0 sec, test acc 0.10\n",
      "epoch 2, time 8.2 sec, test acc 0.67\n",
      "epoch 3, time 8.7 sec, test acc 0.77\n",
      "epoch 4, time 8.7 sec, test acc 0.75\n",
      "epoch 5, time 8.6 sec, test acc 0.79\n",
      "epoch 6, time 8.5 sec, test acc 0.79\n",
      "epoch 7, time 8.5 sec, test acc 0.81\n",
      "epoch 8, time 7.8 sec, test acc 0.84\n",
      "epoch 9, time 9.2 sec, test acc 0.82\n",
      "epoch 10, time 8.9 sec, test acc 0.84\n"
     ]
    }
   ],
   "source": [
    "train(num_gpus=4, batch_size=256, lr=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保持批量大小和学习率不变，将使用的GPU数量改为2。可以看到，测试精度的提升同上一个实验中的结果大体相当。因为有额外的通信开销，所以我们并没有看到训练时间的显著降低。因此，我们将在下一节实验计算更加复杂的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on: [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, time 9.4 sec, test acc 0.10\n",
      "epoch 2, time 7.9 sec, test acc 0.59\n",
      "epoch 3, time 9.1 sec, test acc 0.65\n",
      "epoch 4, time 9.5 sec, test acc 0.72\n",
      "epoch 5, time 8.5 sec, test acc 0.80\n",
      "epoch 6, time 8.8 sec, test acc 0.81\n",
      "epoch 7, time 8.7 sec, test acc 0.74\n",
      "epoch 8, time 7.8 sec, test acc 0.82\n",
      "epoch 9, time 8.9 sec, test acc 0.84\n",
      "epoch 10, time 8.4 sec, test acc 0.83\n"
     ]
    }
   ],
   "source": [
    "train(num_gpus=4, batch_size=256, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on: [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, time 14.3 sec, test acc 0.17\n",
      "epoch 2, time 14.5 sec, test acc 0.62\n",
      "epoch 3, time 11.5 sec, test acc 0.69\n",
      "epoch 4, time 12.6 sec, test acc 0.77\n",
      "epoch 5, time 12.7 sec, test acc 0.80\n",
      "epoch 6, time 13.0 sec, test acc 0.75\n",
      "epoch 7, time 13.2 sec, test acc 0.79\n",
      "epoch 8, time 12.9 sec, test acc 0.82\n",
      "epoch 9, time 11.4 sec, test acc 0.85\n",
      "epoch 10, time 12.2 sec, test acc 0.81\n"
     ]
    }
   ],
   "source": [
    "train(num_gpus=4, batch_size=256, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on: [gpu(0), gpu(1), gpu(2), gpu(3)]\n",
      "epoch 1, time 14.6 sec, test acc 0.10\n",
      "epoch 2, time 13.0 sec, test acc 0.60\n",
      "epoch 3, time 13.4 sec, test acc 0.75\n",
      "epoch 4, time 12.1 sec, test acc 0.73\n",
      "epoch 5, time 12.7 sec, test acc 0.76\n",
      "epoch 6, time 12.1 sec, test acc 0.81\n",
      "epoch 7, time 13.0 sec, test acc 0.73\n",
      "epoch 8, time 10.9 sec, test acc 0.78\n",
      "epoch 9, time 10.7 sec, test acc 0.81\n",
      "epoch 10, time 13.3 sec, test acc 0.81\n"
     ]
    }
   ],
   "source": [
    "train(num_gpus=4, batch_size=256, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1c499ea8706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss_curve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_curve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_curve=[]\n",
    "train(num_gpus=4, batch_size=256, lr=0.2)\n",
    "plt.plot(loss_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(loss_curve[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1,2,3,4])\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
